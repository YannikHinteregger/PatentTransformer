
# PatentTransformer

PatentTransformer is our codename for "Augmented Inventing." The ultimate goal of this project is to help inventors conceive better inventions and quality patents. We leverage Transformer-based models, such as GPT-2 and BERT for patent text generation and measurement. Our source code will be released soon.

## Our preprints & papers

  * [Patent Claim Generation by Fine-Tuning OpenAI GPT-2](https://arxiv.org/abs/1907.02052) (to be published by the [World Patent Information Journal](https://www.journals.elsevier.com/world-patent-information))
  * [Measuring Patent Claim Generation by Span Relevancy](https://arxiv.org/abs/1908.09591) (To be published in the Proceedings of the Thirteenth International Workshop on Juris-informatics (JURISIN 2019), hosted by JSAI-isAI2019)
  * [Personalized Patent Claim Generation and Measurement](https://arxiv.org/abs/1912.03502) (Best Doctoral Consortium paper at the 32nd International Conference on Legal Knowledge and Information Systems (JURIX 2019). To be published in the CEUR Workshop Proceedings)
  * [Measuring and Controlling Text Generation by Semantic Search: A Textual Similarity Approach for PatentTransformer](https://www.researchgate.net/publication/338964985_Measuring_and_Controlling_Text_Generation_by_Semantic_Search_A_Textual_Similarity_Approach_for_PatentTransformer) (accepted, PhD Symposium of The Web Conference 2020 (formerly known as WWW conference))
  * [PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model](https://arxiv.org/abs/1906.02124) ([World Patent Information Journal, 2020-06-01](https://www.researchgate.net/publication/341812065_Patent_classification_by_fine-tuning_BERT_language_model))
  * [Controlling Patent Text Generation by Structural Metadata](https://arxiv.org/abs/2001.03708) (under review)

## License

[GNU General Public License v3.0](LICENSE)
